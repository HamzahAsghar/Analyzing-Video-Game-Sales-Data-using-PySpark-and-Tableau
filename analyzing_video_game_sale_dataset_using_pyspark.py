# -*- coding: utf-8 -*-
"""Analyzing Video Game Sale Dataset using PySpark

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X0H7ncPlTdVhKwEXK9YINGKgOCm4LGrO
"""

!pip install pyspark

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql import *
from pyspark.sql import SparkSession
from pyspark.ml.stat import Correlation
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml import Pipeline

# Start Spark Session
spark = SparkSession.builder \
    .master("local") \
    .appName("Video Game Sales Analysis") \
    .config('spark.ui.port', '4050') \
    .getOrCreate()

# Read the CSV file
df = spark.read.csv('/content/vgsales.csv', header=True, inferSchema=True)

# Show first 20 rows
df.show(20)

df_1 = spark.read.option("header", "true").option("mode", "DROPMALFORMED").csv("/content/vgsales.csv")
df.fillna(value=0).show()

df.fillna(value=-99, subset=["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales", "Global_Sales"]).show()

# Calculate Descriptive Statistics
quantitative_columns = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']

# Calculate Mean
mean_values = df.select(*[F.mean(col).alias(f'mean_{col}') for col in quantitative_columns]).collect()[0]

# Calculate Median
median_values = df.select(*[F.expr(f'percentile_approx({col}, 0.5)').alias(f'median_{col}') for col in quantitative_columns]).collect()[0]

# Calculate Standard Deviation
stddev_values = df.select(*[F.stddev(col).alias(f'stddev_{col}') for col in quantitative_columns]).collect()[0]

# Display Descriptive Statistics
for col in quantitative_columns:
    print(f"{col} - Mean: {mean_values[f'mean_{col}']:.2f}, Median: {median_values[f'median_{col}']:.2f}, Std Dev: {stddev_values[f'stddev_{col}']:.2f}")

# Data Exploration
# Total number of rows and columns
print('Rows:', df.count())
print('Columns:', len(df.columns))

# Creating a Pandas DataFrame for plotting
pandas_df = df.toPandas()

# Plotting histograms using Seaborn in the same row
plt.figure(figsize=(20, 6))

plt.subplot(1, 5, 1)
sns.histplot(pandas_df['Global_Sales'], bins=20, kde=True)
plt.title("Global Sales")

plt.subplot(1, 5, 2)
sns.histplot(pandas_df['EU_Sales'], bins=20, kde=True)
plt.title("EU Sales")

plt.subplot(1, 5, 3)
sns.histplot(pandas_df['NA_Sales'], bins=20, kde=True)
plt.title("NA Sales")

plt.subplot(1, 5, 4)
sns.histplot(pandas_df['JP_Sales'], bins=20, kde=True)
plt.title("JP Sales")

plt.subplot(1, 5, 5)
sns.histplot(pandas_df['Other_Sales'], bins=20, kde=True)
plt.title("Other Sales")

plt.tight_layout()
plt.show()

# Scatter plots using Seaborn in the same row
plt.figure(figsize=(15, 5))

# Global Sales vs Year
plt.subplot(1, 5, 1)
sns.scatterplot(x='Global_Sales', y='Year', data=pandas_df.sort_values('Year'))
plt.title("Global Sales vs Year")
plt.xlabel("Global Sales")
plt.ylabel("Year")

# EU Sales vs Year
plt.subplot(1, 5, 2)
sns.scatterplot(x='EU_Sales', y='Year', data=pandas_df.sort_values('Year'))
plt.title("EU Sales vs Year")
plt.xlabel("EU Sales")
plt.ylabel("Year")

# NA Sales vs Year
plt.subplot(1, 5, 3)
sns.scatterplot(x='NA_Sales', y='Year', data=pandas_df.sort_values('Year'))
plt.title("NA Sales vs Year")
plt.xlabel("NA Sales")
plt.ylabel("Year")

# JP Sales vs Year
plt.subplot(1, 5, 4)
sns.scatterplot(x='JP_Sales', y='Year', data=pandas_df.sort_values('Year'))
plt.title("JP Sales vs Year")
plt.xlabel("JP Sales")
plt.ylabel("Year")

# Other Sales vs Year
plt.subplot(1, 5, 5)
sns.scatterplot(x='Other_Sales', y='Year', data=pandas_df.sort_values('Year'))
plt.title("Other Sales vs Year")
plt.xlabel("Other Sales")
plt.ylabel("Year")

plt.tight_layout()
plt.show()

# Box plot using Seaborn
plt.figure(figsize=(10, 6))
sns.boxplot(x='Genre', y='Global_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Box Plot: Global Sales by Genre")
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Genre', y='EU_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Box Plot: EU Sales by Genre")
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Genre', y='JP_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Box Plot: JP Sales by Genre")
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Genre', y='NA_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Box Plot: NA Sales by Genre")
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Genre', y='Other_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Box Plot: other Sales by Genre")
plt.show()

# Creating bar plots using Matplotlib
plt.figure(figsize=(10, 6))
sns.barplot(x='Platform', y='EU_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("EU sales by Platform")
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Platform', y='Global_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Global sales by Platform")
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Platform', y='NA_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("NA sales by Platform")
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Platform', y='JP_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("JP sales by Platform")
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Platform', y='Other_Sales', data=pandas_df)
plt.xticks(rotation=45)
plt.title("Other sales by Platform")
plt.show()

# Unique Values in 'genre' Column
df.select('Genre').distinct().show()

# Distribution of values inside column 'genre'
df.groupBy('genre').count().show()

# Unique Values in 'Platform' Column
df.select('Platform').distinct().show()

# Distribution of values inside column 'Platform'
df.groupBy('Platform').count().show()

# Question 1: Top 3 Video Games in sports that Sell the most Globally
df.select('Name', 'Global_Sales').where(df.Genre == 'Sports').orderBy('Global_Sales', ascending=False).show(3)

# Question 2: Top 5 Publisher in Racing who Have highest sale in Europe
df.select('Publisher', 'EU_Sales').filter(df.Genre == 'Racing').orderBy('EU_Sales', ascending=False).show(5)

# Question 3: Name 5 lowest Sales Publisher Globally
df.select('Publisher', 'Global_Sales').orderBy('Global_Sales', ascending=True).show(5)

# Question 4: Average sale for various genres
df.groupBy('Genre').agg(F.round(F.mean('Global_Sales'), 2).alias('average_sales')).show()

# Question 5: List of Name with sale in 2015
df.select('Name', 'Publisher', 'Global_Sales').where(df.Year == '2015').orderBy('Global_Sales', ascending=False).show()

# Describe the DataFrame
df.describe().show()

# Linear Regression Analysis
data = df.select("NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales", "Global_Sales").dropna()
feature_columns = ["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
data = assembler.transform(data)
train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)
lr = LinearRegression(featuresCol="features", labelCol="Global_Sales")
pipeline = Pipeline(stages=[lr])
lr_model = pipeline.fit(train_data)
predictions = lr_model.transform(test_data)
evaluator = RegressionEvaluator(labelCol="Global_Sales", metricName="rmse")
rmse = evaluator.evaluate(predictions)
print("Linear Regression RMSE:", rmse)
lr_coefficients = lr_model.stages[-1].coefficients
print("Linear Regression Coefficients:", lr_coefficients)

# Logistic Regression Analysis
data = df.select("NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales", "Global_Sales").dropna()
data = data.withColumn("TopSeller", (data["Global_Sales"] > 1).cast("int"))
feature_columns = ["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
data = assembler.transform(data)
train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)
lr = LogisticRegression(featuresCol="features", labelCol="TopSeller")
pipeline = Pipeline(stages=[lr])
lr_model = pipeline.fit(train_data)
predictions = lr_model.transform(test_data)
evaluator = BinaryClassificationEvaluator(labelCol="TopSeller")
accuracy = evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})
print("Logistic Regression Area under ROC:", accuracy)

# Random Forest Classifier Analysis
data = df.select("NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales", "Global_Sales").dropna()
data = data.withColumn("TopSeller", (data["Global_Sales"] > 1).cast("int"))
feature_columns = ["NA_Sales", "EU_Sales", "JP_Sales", "Other_Sales"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
data = assembler.transform(data)
train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)
rf = RandomForestClassifier(featuresCol="features", labelCol="TopSeller")
pipeline = Pipeline(stages=[rf])
rf_model = pipeline.fit(train_data)
predictions = rf_model.transform(test_data)
evaluator = BinaryClassificationEvaluator(labelCol="TopSeller")
accuracy = evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})
print("Random Forest Classifier Area under ROC:", accuracy)

# Stop the Spark session
spark.stop()